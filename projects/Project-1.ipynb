{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9qv6dWZPsroB"
   },
   "source": [
    "# Project 1\n",
    "Complete each of the exercises below. Write your code only in the cells containing the message:\n",
    "\n",
    "<font color='green'>############ Your code goes here ##################\n",
    "\n",
    "###################################################\n",
    "</font>\n",
    "  \n",
    "Do **NOT** change any other code. You can create new code cells to try things however before you submit the project please delete them. \n",
    "\n",
    "You are provided test functions for some of the exercises. In order to be able to run the tests you need to run the code cell below everytime you open this notebook or reset the runtime. \n",
    "  \n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsaUovntxj-E"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "import os \n",
    "\n",
    "if not os.path.isdir('MATH448001'):\n",
    "    !git clone https://github.com/iuls/MATH448001.git\n",
    "\n",
    "from MATH448001.project_tests import project_1_tests\n",
    "from MATH448001.project_utils import project_1_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pv6W34NwNSjn"
   },
   "source": [
    "# Exercise 1 (5 points)\n",
    "\n",
    "Write a function that takes a 2D numpy array as its argument and returns the average of the columns as an array. For example if the input array is `[[1,2],[3,4]]`, then the function will return `[2, 3]` since the average of the first column is $(1+3)/2=2$ and the second column is $(2+4)/2=3$.\n",
    "\n",
    "Hint: Check out [`np.mean()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rnmr6j0NPkWV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def column_means(arr):\n",
    "  \n",
    "    ########## Your code goes here #############\n",
    "\n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    return column_means \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQ8Yt_rgYXL0"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_column_means(column_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9E2Gt6PPGTq"
   },
   "source": [
    "# Exercise 2 (10 points)\n",
    "\n",
    "Implement a function that takes an array and a threshold value as arguments and returns an array where all the values of the input array above the threshold are replaced by the threshold value. \n",
    "For example if the input array is `[[5,2],[3,4]]` and threshold = 3, then the function will return `[[3,2],[3,3]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tc_UadcRO4TN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cutoff(arr, threshold):\n",
    "  \n",
    "    ########## Your code goes here #############\n",
    "    \n",
    "    ############################################  \n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_oR-nWSdNGC"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_cutoff(cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KyGlJ9naRPL0"
   },
   "source": [
    "# Exercise 3 (5 points)\n",
    "\n",
    "Implement a function that takes a 2D array as its argument and returns the indices of the maximum values of each row as an array. For example if the input array is `[[5,2],[3,4]]`, then the function will return `[0,1]` since the max value in the first row (which is 5) is at index 0 and the max value in the second row (which is 4) is at index 1.  \n",
    "\n",
    "Hint: Check out [`np.argmax()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAjj3UdTQBlO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_max_index(arr):\n",
    "  \n",
    "    ########## Your code goes here #############\n",
    "\n",
    "    ############################################ \n",
    "    \n",
    "    return max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2Pb9aUbfvlY"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_max_index(find_max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGyIDQmMZPen"
   },
   "source": [
    "# Exercise 4 (10 points)\n",
    "\n",
    "Implement a function that takes an array `W` of shape $(m,n)$, an array `x` of shape $(1,m)$ and an array `b` of shape $(1,n)$ and returns the result of the following operation\n",
    "$$\n",
    "z = xW + b\n",
    "$$\n",
    "For example if \n",
    "$$\n",
    "W = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\quad x = \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\quad  b = \\begin{bmatrix} 3 & -1 \\end{bmatrix}\n",
    "$$\n",
    "then \n",
    "$$\n",
    "z = \\begin{bmatrix} 7 & 5 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Hint: Check out [`np.matmul()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aqqbQY5SQ4Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear(W, x, b):\n",
    "    \n",
    "    ########## Your code goes here #############\n",
    "\n",
    "    \n",
    "    ############################################\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfzXVKGE63ON"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_linear(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8LSzq-DSN6O"
   },
   "source": [
    "# Exercise 5 (5 points)\n",
    "\n",
    "Implement a function that takes two integer arguments $n$ and $m$ and returns a random numpy array of shape $(n,m)$ where the entries are sampled from a uniform distribution over $[-1,1]$. \n",
    "\n",
    "Hint: Take a look at [this](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html) to see the available probability distributions in numpy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXhBP7Cc0nM-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def uniform_matrix(n,m):\n",
    "\n",
    "    np.random.seed(seed = 1)\n",
    "\n",
    "    ########## Your code goes here #############\n",
    "\n",
    "    \n",
    "    ############################################\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGlQBd2MTgMT"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_uniform_matrix(uniform_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0p0UnM2smSW"
   },
   "source": [
    "# Exercise 6 (5 points)\n",
    "\n",
    "Implement a function that takes two vectors (1D numpy arrays) in $\\mathbb{R}^n$ as its arguments and returns True if these vectors are orthogonal and False otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lA_gNdQIs4ry"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_orthogonal(v1, v2):\n",
    "\n",
    "    ########## Your code goes here #############\n",
    "\n",
    "\n",
    "\n",
    "    ############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjL36RzOtKNK"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_orthogonal(is_orthogonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mp_HnEBdt3cx"
   },
   "source": [
    "# Exercise 7 (5 points)\n",
    "\n",
    "An $n\\times n$ matrix is called an orthogonal matrix if its columns form an **orthonormal** basis for $\\mathbb{R}^n$. This implies that $A$ is orthogonal if and only if\n",
    "$$\n",
    "A^{-1} = A^T\n",
    "$$\n",
    "if and only if \n",
    "$$\n",
    "A^TA = AA^T = I\n",
    "$$\n",
    "Example: For any $\\theta$, the matrix \n",
    "$$\n",
    "\\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}\n",
    "$$\n",
    "is an orthogonal matrix. \n",
    "\n",
    "Implement a function that takes $\\theta$ as its argument and returns the above orthogonal matrix as a 2D numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_oLLBOOHvoMe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rotation(theta):\n",
    "\n",
    "    ########## Your code goes here #############\n",
    "\n",
    "    ############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHCAwxSKwoCg"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_rotation(rotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8SozJiuGRLm"
   },
   "source": [
    "# Exercise 8 (5 points)\n",
    "\n",
    "A Bernoulli random variable is a discrete random variable $X$ with two possible values 0 and 1. So the Bernoulli distribution is completely determined by a single parameter $p$, the probability that $X$ takes the value $1$. Hence $$\\mathbb{P}(X = 1) = p$$ and $$\\mathbb{P}(X = 0) = 1- p$$ \n",
    "You can think of this as a single toss of a possibly unfair coin. \n",
    "\n",
    "A Binomial random variable $X$ with parameters $n$ and $p$ is defined as the sum of $n$ independent, identically distributed (iid) Bernoulli random variables with parameter p. In other words, $X$ is the number of $1$s in $n$ Bernoulli trials. You can think of this as the number of heads observed after tossing a coin $n$ times which has probability of heads $p$. Hence for $n=1$, the Binomial distribution is equal to the Bernoulli distribution. \n",
    "\n",
    "Implement a function that simulates $m$ coin tosses by generating $m$ sample values from a Bernoulli distribution. The function takes $p$ and $m$ as its arguments and returns an array of 0s and 1s corresponding to the $m$ coin tosses. \n",
    "\n",
    "Hint: You can use the [`np.random.binomial()`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.binomial.html#numpy.random.binomial) function with $n=1$ to simulate a single coin toss. You can use the `size` argument to repeat the sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Upd1fnKmJnAe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def coin_toss(m,p):\n",
    "    \n",
    "    # This line makes it sure that the random samples generated are the same in \n",
    "    # different runs of this function. It is only needed for test purposes.  \n",
    "    np.random.seed(seed = 1)\n",
    "\n",
    "    ########## Your code goes here #############\n",
    "\n",
    "\n",
    "    ############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oRvHQ2sYi25"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_coin_toss(coin_toss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6WgW9rvAP66z"
   },
   "outputs": [],
   "source": [
    "coin_toss(100, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgCNmPcuIfez"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "```array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
    "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
    "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
    "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
    "       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1])```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmkAUHwAMMTk"
   },
   "source": [
    "# Exercise 9 (5 points)\n",
    "\n",
    "A Multinoulli random variable $X$ is a discrete random variable with $k$ discrete values $c_1, \\ldots, c_k$. The probability distribution is determined by a vector $p = [p_1, \\ldots, p_k]\\in [0,1]^k$ such that $\\sum_i p_i = 1$ and\n",
    "$$\n",
    "\\mathbb{P}(X = c_i) = p_i \\quad i = 1, \\ldots, k\n",
    "$$\n",
    "Think of it as a $k$-sided die roll where the probabilities of each side is given by $p$.\n",
    "\n",
    "A Multinomial random variable $X$ with parameters $n$ and $p\\in [0,1]^k$ is defined as the sum of $n$ independent identically distributed Multinoulli variables. In other words, $X$ is the number of each value in $n$ repetitions of a Multinoulli trial. You can think of it as the frequency of the face values observed after $n$ rolls of a $k$-sided die. A Multinomial random variable with $n=1$ simulates a single $k$-sided die roll. The values taken by such a random variable are vectors consisting of 0s with a single 1 at the index corresponding to the outcome of the die roll. For example, $[0,0,0,1,0,0]$ means that the outcome of the $6$-sided die roll was $c_4$. \n",
    "\n",
    "\n",
    "Implement a function that simulates $m$ rolls of an unfair die with $k$ sides numbered 1 through k. The function takes $m$ and the probability vector $p$ (of length $k$) as its arguments and returns a 2D array where each row consists of $k$ zeros except a single $1$ corresponding to the outcome of the die roll. \n",
    "\n",
    "Hint: You can use [`np.random.multinomial`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.multinomial.html#numpy.random.multinomial) with n = 1. Your solution to Exercise 10 may help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pso2lianOUR6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def die_roll(m, p):\n",
    "\n",
    "    np.random.seed(seed = 1)\n",
    "    ########## Your code goes here #############\n",
    "\n",
    "    ############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUjM3VkdQivU"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_die_roll(die_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpPLK0OSOyvP"
   },
   "outputs": [],
   "source": [
    "# 30 rolls of a fair die.\n",
    "die_roll(30, [1/6]*6 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zj3B5KU_InA6"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "array([[0, 0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1],\n",
    "       [0, 1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0, 0],\n",
    "       [0, 0, 0, 1, 0, 0],\n",
    "       [1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 0, 1, 0],\n",
    "       [0, 1, 0, 0, 0, 0],\n",
    "       [0, 1, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0, 0],\n",
    "       [0, 0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 1, 0],\n",
    "       [0, 1, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 1, 0],\n",
    "       [0, 0, 0, 0, 1, 0],\n",
    "       [1, 0, 0, 0, 0, 0]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lm6yRKeOT3PQ"
   },
   "source": [
    "# Exercise 10 (5 points)\n",
    "\n",
    "For a discrete random variable $X$ with a probability mass function $P$, the expected value of $X$ is defined as \n",
    "$$\n",
    "\\mathbb{E}[X] = \\sum_xP(x)x\n",
    "$$\n",
    "where the sum is over all possible values of $X$. For a function $f$ defined over the sample space of $X$, the expected value of $f$ with respect to the distribution $P$ is defined as,\n",
    "$$\n",
    "\\mathbb{E}_{x\\sim P}[f(x)] = \\sum_x P(x)f(x)\n",
    "$$\n",
    "\n",
    "Implement a function that computes the expected value of a function with respect to a distribution $P$. The function takes two arguments: \n",
    "  - $f = [f(x_1), \\ldots, f(x_N)]$, a 1D numpy array consisting of the value of the function $f$ at each possible value of $X$\n",
    "  - $P = [p_1, \\ldots, p_N]$, a 1D numpy array consisting of probabilities of each possible value of $X$, i.e. $\\mathbb{P}(X= x_i) = p_i$.\n",
    "\n",
    "and returns $\\mathbb{E}_{x\\sim P}[f(x)]$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VQWP9cfdHrZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def expected_value(f, P):\n",
    "    ########## Your code goes here #############\n",
    "\n",
    "    ############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Hg8E43oWGuT"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_expected_value(expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CkEpc-gWwdci"
   },
   "source": [
    "# Exercise 11 (5 points)\n",
    "\n",
    "Let $P$ and $Q$ be two probability distributions over the same sample space. The KL-divergence is a measure of how different these two distributions are from one another:\n",
    "$$\n",
    "D_{KL}(P||Q) := \\mathbb{E}_{x\\sim P}[\\log P(x) - \\log Q(x)] = \\mathbb{E}_{x\\sim P}[\\log P(x)] - \\mathbb{E}_{x\\sim P}[\\log Q(x)]\n",
    "$$\n",
    "\n",
    "Note that the above formula is not symmetric with respect to $P$ and $Q$. \n",
    "\n",
    "The distribution $P$ often represents an empirical distribution given by observed data from a data generating process and $Q$ the distribution modeling this process. The KL-divergence measures how well the model $Q$ describes the data generating process. See an example [here](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Basic_example). \n",
    "\n",
    "Implement a function that computes the KL-divergence of two distributions. The function takes two arguments:\n",
    " - $P$: a 1D numpy array consisting of probabilities with respect to $P$.\n",
    " - $Q$: a 1D numpy array consisting of probabilities with respect to $Q$. \n",
    "\n",
    "and returns $D_{KL}(P||Q)$.   \n",
    "\n",
    "Hint: The `expected_value` function from Exercise 10 can be helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oc3j8_Suy_4f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kl_divergence(P, Q):\n",
    "\n",
    "    ########## Your code goes here #############\n",
    "\n",
    "\n",
    "    ############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0q5zzxbY2gsY"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_kl_divergence(kl_divergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BS_03SRNAS9P"
   },
   "source": [
    "# Exercise 12 (25 points)\n",
    "\n",
    "In this exercise you will implement the perceptron algorithm through the origin. \n",
    "\n",
    "First implement the prediction function that takes weights $\\vec{\\bf{w}}$ and input vector $\\vec{\\bf{x}}$ and returns the prediction of the model. The function describing the model is denoted as $h_{\\vec{\\bf{w}},0}(\\vec{\\bf{x}})$ and is defined as\n",
    "$$\n",
    "h_{\\vec{\\bf{w}},0}(\\vec{\\bf{x}}) = \\begin{cases}\n",
    "+1 \\quad \\text{ if } \\vec{\\bf{w}}\\cdot \\vec{\\bf{x}} > 0 \\\\\n",
    "-1 \\quad \\text{ if } \\vec{\\bf{w}}\\cdot \\vec{\\bf{x}} \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The function takes two arguments $\\vec{\\bf{w}}$ and $\\vec{\\bf{x}}$ and returns $1$ or $-1$ according to the above definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4SgcP2ZASpQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def h(w, x):\n",
    "\n",
    "    ########## Your code goes here #############\n",
    "\n",
    "    \n",
    "    ############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbdzP4QenKsV"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_prediction(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGufyO1CCRKk"
   },
   "source": [
    "Now you will implement the perceptron algorithm through the origin. The function below takes the training data and the labels as arguments and returns the learned weights. The training loop is already given: it loops over the training data 10 times. Implement the weight update step:\n",
    "$$\n",
    "\\vec{\\bf{w}} = \\vec{\\bf{w}} + y^{(i)}\\vec{\\bf{x}}^{(i)}\n",
    "$$\n",
    "if the $i$th example is misclassified. If the $i$th example is classified correctly, $\\vec{\\bf{w}}$ is not updated. \n",
    "\n",
    "`x_train` below is a 2D numpy array of shape $(n, 2)$ where $n$ is the number of training examples. Each row of `x_train` is an example in training data. You can get the $i$th example $\\vec{\\bf{x}}^{(i)}$ as `x_train[i]` and the corresponding label $y^{(i)}$ as `y_train[i]`. Use the prediction function, $h$, you implemented above to check if a given example is misclassified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mCaIusWCPgP"
   },
   "outputs": [],
   "source": [
    "def perceptron_through_origin(x_train,y_train):\n",
    "    #number of data points\n",
    "    num_data = len(x_train)\n",
    "\n",
    "    #initialize the weights\n",
    "    w = np.array([0,0])\n",
    "\n",
    "    for i in range(10):\n",
    "        for i in range(num_data):\n",
    "            ########## Your code goes here #############\n",
    "            #TODO: Check if the ith example is misclassified and update w if it is.\n",
    "\n",
    "            ############################################\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LR57-obAExrh"
   },
   "outputs": [],
   "source": [
    "project_1_tests.test_perceptron(perceptron_through_origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PK-PmkL7FVEP"
   },
   "source": [
    "Let's apply the perceptron algorithm you implemented above. The following code cell is loading an artificial dataset and plotting it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8QdzMceE2mg"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = project_1_utils.load_data()\n",
    "project_1_utils.plot_data(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSCMj6m1Fvkt"
   },
   "source": [
    "Now run the perceptron algorithm on this dataset and get the weights learned by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMDfoezpFuZP"
   },
   "outputs": [],
   "source": [
    "w = perceptron_through_origin(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSX9hDe6F92M"
   },
   "source": [
    "Let's plot the decision boundary learned by the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIsZalXfF8X_"
   },
   "outputs": [],
   "source": [
    "project_1_utils.plot_data(x_train, y_train)\n",
    "project_1_utils.plot_decision_boundary(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project-1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
